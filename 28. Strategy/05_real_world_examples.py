"""
05_real_world_examples.py - å®é™…é¡¹ç›®ä¸­çš„ç­–ç•¥æ¨¡å¼åº”ç”¨

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†ç­–ç•¥æ¨¡å¼åœ¨å®é™…é¡¹ç›®ä¸­çš„å¤æ‚åº”ç”¨åœºæ™¯ï¼Œ
åŒ…æ‹¬æ–‡ä»¶å‹ç¼©ã€å›¾åƒå¤„ç†ã€ç¼“å­˜ç®¡ç†ç­‰ç³»ç»Ÿã€‚
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Tuple, Union
import os
import time
import random
import hashlib
from datetime import datetime, timedelta
from enum import Enum
import threading


# ==================== æ–‡ä»¶å‹ç¼©ç­–ç•¥ç³»ç»Ÿ ====================

class CompressionStrategy(ABC):
    """æ–‡ä»¶å‹ç¼©ç­–ç•¥æŠ½è±¡ç±»"""
    
    @abstractmethod
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """å‹ç¼©æ•°æ®ï¼Œè¿”å›å‹ç¼©åçš„æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯"""
        pass
    
    @abstractmethod
    def decompress(self, compressed_data: bytes) -> bytes:
        """è§£å‹æ•°æ®"""
        pass
    
    @abstractmethod
    def get_algorithm_name(self) -> str:
        """è·å–ç®—æ³•åç§°"""
        pass
    
    @abstractmethod
    def get_compression_level(self) -> int:
        """è·å–å‹ç¼©çº§åˆ« (1-10)"""
        pass
    
    @abstractmethod
    def is_suitable_for_file_type(self, file_extension: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦é€‚åˆç‰¹å®šæ–‡ä»¶ç±»å‹"""
        pass


class ZipCompressionStrategy(CompressionStrategy):
    """ZIPå‹ç¼©ç­–ç•¥"""
    
    def __init__(self, compression_level: int = 6):
        self.compression_level = min(10, max(1, compression_level))
    
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """æ¨¡æ‹ŸZIPå‹ç¼©"""
        start_time = time.time()
        
        # æ¨¡æ‹Ÿå‹ç¼©è¿‡ç¨‹
        time.sleep(0.01)  # æ¨¡æ‹Ÿå‹ç¼©æ—¶é—´
        
        # æ¨¡æ‹Ÿå‹ç¼©æ•ˆæœï¼ˆæ ¹æ®å‹ç¼©çº§åˆ«ï¼‰
        compression_ratio = 0.3 + (self.compression_level / 10) * 0.4  # 30%-70%å‹ç¼©ç‡
        compressed_size = int(len(data) * compression_ratio)
        compressed_data = data[:compressed_size]  # æ¨¡æ‹Ÿå‹ç¼©æ•°æ®
        
        compression_time = time.time() - start_time
        
        stats = {
            'original_size': len(data),
            'compressed_size': compressed_size,
            'compression_ratio': (len(data) - compressed_size) / len(data) * 100,
            'compression_time': compression_time,
            'algorithm': self.get_algorithm_name()
        }
        
        return compressed_data, stats
    
    def decompress(self, compressed_data: bytes) -> bytes:
        """æ¨¡æ‹ŸZIPè§£å‹"""
        time.sleep(0.005)  # æ¨¡æ‹Ÿè§£å‹æ—¶é—´
        # æ¨¡æ‹Ÿè§£å‹è¿‡ç¨‹ï¼Œå®é™…åº”è¯¥æ¢å¤åŸå§‹æ•°æ®
        return compressed_data * 2  # ç®€å•æ¨¡æ‹Ÿ
    
    def get_algorithm_name(self) -> str:
        return f"ZIP (çº§åˆ« {self.compression_level})"
    
    def get_compression_level(self) -> int:
        return self.compression_level
    
    def is_suitable_for_file_type(self, file_extension: str) -> bool:
        """ZIPé€‚åˆå¤§å¤šæ•°æ–‡ä»¶ç±»å‹"""
        return file_extension.lower() in ['.txt', '.doc', '.pdf', '.html', '.xml', '.csv']


class GzipCompressionStrategy(CompressionStrategy):
    """GZIPå‹ç¼©ç­–ç•¥"""
    
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """æ¨¡æ‹ŸGZIPå‹ç¼©"""
        start_time = time.time()
        time.sleep(0.008)
        
        # GZIPé€šå¸¸æœ‰æ›´å¥½çš„å‹ç¼©ç‡ä½†é€Ÿåº¦ç¨æ…¢
        compression_ratio = 0.25
        compressed_size = int(len(data) * compression_ratio)
        compressed_data = data[:compressed_size]
        
        compression_time = time.time() - start_time
        
        stats = {
            'original_size': len(data),
            'compressed_size': compressed_size,
            'compression_ratio': (len(data) - compressed_size) / len(data) * 100,
            'compression_time': compression_time,
            'algorithm': self.get_algorithm_name()
        }
        
        return compressed_data, stats
    
    def decompress(self, compressed_data: bytes) -> bytes:
        time.sleep(0.004)
        return compressed_data * 3  # ç®€å•æ¨¡æ‹Ÿ
    
    def get_algorithm_name(self) -> str:
        return "GZIP"
    
    def get_compression_level(self) -> int:
        return 8  # GZIPé»˜è®¤çº§åˆ«
    
    def is_suitable_for_file_type(self, file_extension: str) -> bool:
        """GZIPç‰¹åˆ«é€‚åˆæ–‡æœ¬æ–‡ä»¶"""
        return file_extension.lower() in ['.txt', '.log', '.json', '.xml', '.html', '.css', '.js']


class LZ4CompressionStrategy(CompressionStrategy):
    """LZ4å‹ç¼©ç­–ç•¥ - é«˜é€Ÿå‹ç¼©"""
    
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """æ¨¡æ‹ŸLZ4å‹ç¼©"""
        start_time = time.time()
        time.sleep(0.003)  # LZ4é€Ÿåº¦å¾ˆå¿«
        
        # LZ4å‹ç¼©ç‡è¾ƒä½ä½†é€Ÿåº¦å¾ˆå¿«
        compression_ratio = 0.5
        compressed_size = int(len(data) * compression_ratio)
        compressed_data = data[:compressed_size]
        
        compression_time = time.time() - start_time
        
        stats = {
            'original_size': len(data),
            'compressed_size': compressed_size,
            'compression_ratio': (len(data) - compressed_size) / len(data) * 100,
            'compression_time': compression_time,
            'algorithm': self.get_algorithm_name()
        }
        
        return compressed_data, stats
    
    def decompress(self, compressed_data: bytes) -> bytes:
        time.sleep(0.001)  # è§£å‹ä¹Ÿå¾ˆå¿«
        return compressed_data * 2
    
    def get_algorithm_name(self) -> str:
        return "LZ4 (é«˜é€Ÿ)"
    
    def get_compression_level(self) -> int:
        return 3  # ä½å‹ç¼©çº§åˆ«ï¼Œé«˜é€Ÿåº¦
    
    def is_suitable_for_file_type(self, file_extension: str) -> bool:
        """LZ4é€‚åˆéœ€è¦å¿«é€Ÿå‹ç¼©çš„åœºæ™¯"""
        return file_extension.lower() in ['.log', '.tmp', '.cache', '.db']


# ==================== æ–‡ä»¶å‹ç¼©ç®¡ç†å™¨ ====================

class FileCompressionManager:
    """æ–‡ä»¶å‹ç¼©ç®¡ç†å™¨"""
    
    def __init__(self):
        self._strategies: Dict[str, CompressionStrategy] = {
            'zip': ZipCompressionStrategy(),
            'zip_fast': ZipCompressionStrategy(compression_level=3),
            'zip_best': ZipCompressionStrategy(compression_level=9),
            'gzip': GzipCompressionStrategy(),
            'lz4': LZ4CompressionStrategy()
        }
        self._compression_history: List[Dict[str, Any]] = []
    
    def compress_file(self, file_path: str, strategy_name: str = None) -> Dict[str, Any]:
        """å‹ç¼©æ–‡ä»¶"""
        if not os.path.exists(file_path):
            return {'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}
        
        # è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
        if strategy_name is None:
            strategy_name = self._auto_select_strategy(file_path)
        
        if strategy_name not in self._strategies:
            return {'success': False, 'error': f'ä¸æ”¯æŒçš„å‹ç¼©ç­–ç•¥: {strategy_name}'}
        
        strategy = self._strategies[strategy_name]
        
        try:
            # è¯»å–æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰
            file_size = random.randint(1024, 1024*1024)  # 1KB-1MB
            file_data = b'x' * file_size  # æ¨¡æ‹Ÿæ–‡ä»¶æ•°æ®
            
            print(f"ğŸ“ å‹ç¼©æ–‡ä»¶: {file_path}")
            print(f"ğŸ”§ ä½¿ç”¨ç­–ç•¥: {strategy.get_algorithm_name()}")
            print(f"ğŸ“Š åŸå§‹å¤§å°: {file_size:,} å­—èŠ‚")
            
            # æ‰§è¡Œå‹ç¼©
            compressed_data, stats = strategy.compress(file_data)
            
            # è®°å½•å†å²
            history_record = {
                'file_path': file_path,
                'strategy': strategy_name,
                'timestamp': datetime.now(),
                **stats
            }
            self._compression_history.append(history_record)
            
            print(f"âœ… å‹ç¼©å®Œæˆ:")
            print(f"   å‹ç¼©åå¤§å°: {stats['compressed_size']:,} å­—èŠ‚")
            print(f"   å‹ç¼©ç‡: {stats['compression_ratio']:.1f}%")
            print(f"   å‹ç¼©æ—¶é—´: {stats['compression_time']:.3f} ç§’")
            
            return {
                'success': True,
                'compressed_data': compressed_data,
                'stats': stats
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _auto_select_strategy(self, file_path: str) -> str:
        """è‡ªåŠ¨é€‰æ‹©å‹ç¼©ç­–ç•¥"""
        file_extension = os.path.splitext(file_path)[1]
        file_size = random.randint(1024, 1024*1024)  # æ¨¡æ‹Ÿæ–‡ä»¶å¤§å°
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹å’Œå¤§å°é€‰æ‹©ç­–ç•¥
        if file_size > 100 * 1024 * 1024:  # å¤§äº100MB
            return 'lz4'  # å¤§æ–‡ä»¶ä¼˜å…ˆè€ƒè™‘é€Ÿåº¦
        elif file_extension.lower() in ['.txt', '.log', '.json']:
            return 'gzip'  # æ–‡æœ¬æ–‡ä»¶ç”¨GZIP
        elif file_extension.lower() in ['.tmp', '.cache']:
            return 'lz4'  # ä¸´æ—¶æ–‡ä»¶ç”¨é«˜é€Ÿå‹ç¼©
        else:
            return 'zip'  # é»˜è®¤ä½¿ç”¨ZIP
    
    def get_compression_statistics(self) -> Dict[str, Any]:
        """è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
        if not self._compression_history:
            return {}
        
        total_files = len(self._compression_history)
        total_original_size = sum(h['original_size'] for h in self._compression_history)
        total_compressed_size = sum(h['compressed_size'] for h in self._compression_history)
        total_time = sum(h['compression_time'] for h in self._compression_history)
        
        # æŒ‰ç­–ç•¥ç»Ÿè®¡
        strategy_stats = {}
        for record in self._compression_history:
            strategy = record['strategy']
            if strategy not in strategy_stats:
                strategy_stats[strategy] = {
                    'count': 0,
                    'total_ratio': 0,
                    'total_time': 0
                }
            strategy_stats[strategy]['count'] += 1
            strategy_stats[strategy]['total_ratio'] += record['compression_ratio']
            strategy_stats[strategy]['total_time'] += record['compression_time']
        
        # è®¡ç®—å¹³å‡å€¼
        for strategy, stats in strategy_stats.items():
            stats['avg_ratio'] = stats['total_ratio'] / stats['count']
            stats['avg_time'] = stats['total_time'] / stats['count']
        
        return {
            'total_files': total_files,
            'total_original_size': total_original_size,
            'total_compressed_size': total_compressed_size,
            'overall_compression_ratio': (total_original_size - total_compressed_size) / total_original_size * 100,
            'total_time': total_time,
            'average_time': total_time / total_files,
            'strategy_statistics': strategy_stats
        }


# ==================== ç¼“å­˜ç­–ç•¥ç³»ç»Ÿ ====================

class CacheStrategy(ABC):
    """ç¼“å­˜ç­–ç•¥æŠ½è±¡ç±»"""
    
    @abstractmethod
    def should_cache(self, key: str, data: Any, metadata: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜"""
        pass
    
    @abstractmethod
    def get_ttl(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """è·å–ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰"""
        pass
    
    @abstractmethod
    def get_priority(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """è·å–ç¼“å­˜ä¼˜å…ˆçº§ (1-10, 10æœ€é«˜)"""
        pass
    
    @abstractmethod
    def get_strategy_name(self) -> str:
        """è·å–ç­–ç•¥åç§°"""
        pass


class LRUCacheStrategy(CacheStrategy):
    """LRUç¼“å­˜ç­–ç•¥"""
    
    def should_cache(self, key: str, data: Any, metadata: Dict[str, Any]) -> bool:
        """æ€»æ˜¯ç¼“å­˜ï¼Œç”±LRUç®—æ³•å†³å®šæ·˜æ±°"""
        return True
    
    def get_ttl(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """æ ¹æ®æ•°æ®å¤§å°è®¾ç½®TTL"""
        data_size = metadata.get('size', 0)
        if data_size > 1024 * 1024:  # å¤§äº1MB
            return 300  # 5åˆ†é’Ÿ
        elif data_size > 1024:  # å¤§äº1KB
            return 1800  # 30åˆ†é’Ÿ
        else:
            return 3600  # 1å°æ—¶
    
    def get_priority(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """æ ¹æ®è®¿é—®é¢‘ç‡è®¾ç½®ä¼˜å…ˆçº§"""
        access_count = metadata.get('access_count', 0)
        if access_count > 100:
            return 9
        elif access_count > 10:
            return 6
        else:
            return 3
    
    def get_strategy_name(self) -> str:
        return "LRUç¼“å­˜ç­–ç•¥"


class TTLCacheStrategy(CacheStrategy):
    """TTLç¼“å­˜ç­–ç•¥"""
    
    def __init__(self, default_ttl: int = 3600):
        self.default_ttl = default_ttl
    
    def should_cache(self, key: str, data: Any, metadata: Dict[str, Any]) -> bool:
        """æ ¹æ®æ•°æ®ç±»å‹å†³å®šæ˜¯å¦ç¼“å­˜"""
        data_type = metadata.get('type', '')
        # ä¸ç¼“å­˜æ•æ„Ÿæ•°æ®
        return data_type not in ['password', 'token', 'secret']
    
    def get_ttl(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """æ ¹æ®æ•°æ®ç±»å‹è®¾ç½®ä¸åŒçš„TTL"""
        data_type = metadata.get('type', '')
        
        ttl_mapping = {
            'user_profile': 1800,    # 30åˆ†é’Ÿ
            'product_info': 3600,    # 1å°æ—¶
            'static_content': 86400, # 24å°æ—¶
            'api_response': 300,     # 5åˆ†é’Ÿ
            'search_result': 600     # 10åˆ†é’Ÿ
        }
        
        return ttl_mapping.get(data_type, self.default_ttl)
    
    def get_priority(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """æ ¹æ®æ•°æ®é‡è¦æ€§è®¾ç½®ä¼˜å…ˆçº§"""
        importance = metadata.get('importance', 'normal')
        
        priority_mapping = {
            'critical': 10,
            'high': 8,
            'normal': 5,
            'low': 2
        }
        
        return priority_mapping.get(importance, 5)
    
    def get_strategy_name(self) -> str:
        return f"TTLç¼“å­˜ç­–ç•¥ (é»˜è®¤{self.default_ttl}ç§’)"


class AdaptiveCacheStrategy(CacheStrategy):
    """è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥"""
    
    def __init__(self):
        self._access_patterns: Dict[str, List[datetime]] = {}
    
    def should_cache(self, key: str, data: Any, metadata: Dict[str, Any]) -> bool:
        """æ ¹æ®è®¿é—®æ¨¡å¼å†³å®šæ˜¯å¦ç¼“å­˜"""
        # è®°å½•è®¿é—®æ—¶é—´
        if key not in self._access_patterns:
            self._access_patterns[key] = []
        
        self._access_patterns[key].append(datetime.now())
        
        # ä¿ç•™æœ€è¿‘1å°æ—¶çš„è®¿é—®è®°å½•
        cutoff_time = datetime.now() - timedelta(hours=1)
        self._access_patterns[key] = [
            t for t in self._access_patterns[key] if t > cutoff_time
        ]
        
        # å¦‚æœ1å°æ—¶å†…è®¿é—®è¶…è¿‡3æ¬¡ï¼Œåˆ™ç¼“å­˜
        return len(self._access_patterns[key]) >= 3
    
    def get_ttl(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """æ ¹æ®è®¿é—®é¢‘ç‡åŠ¨æ€è°ƒæ•´TTL"""
        access_count = len(self._access_patterns.get(key, []))
        
        if access_count > 20:
            return 7200  # 2å°æ—¶
        elif access_count > 10:
            return 3600  # 1å°æ—¶
        elif access_count > 5:
            return 1800  # 30åˆ†é’Ÿ
        else:
            return 600   # 10åˆ†é’Ÿ
    
    def get_priority(self, key: str, data: Any, metadata: Dict[str, Any]) -> int:
        """æ ¹æ®è®¿é—®é¢‘ç‡è®¾ç½®ä¼˜å…ˆçº§"""
        access_count = len(self._access_patterns.get(key, []))
        return min(10, max(1, access_count // 2))
    
    def get_strategy_name(self) -> str:
        return "è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥"


# ==================== ç¼“å­˜ç®¡ç†å™¨ ====================

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, strategy: CacheStrategy):
        self._strategy = strategy
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._cache_stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'total_requests': 0
        }
    
    def set_strategy(self, strategy: CacheStrategy) -> None:
        """è®¾ç½®ç¼“å­˜ç­–ç•¥"""
        self._strategy = strategy
        print(f"ğŸ”„ åˆ‡æ¢ç¼“å­˜ç­–ç•¥: {strategy.get_strategy_name()}")
    
    def get(self, key: str) -> Tuple[Any, bool]:
        """è·å–ç¼“å­˜æ•°æ®"""
        self._cache_stats['total_requests'] += 1
        
        if key in self._cache:
            cache_entry = self._cache[key]
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if datetime.now() < cache_entry['expires_at']:
                self._cache_stats['hits'] += 1
                cache_entry['access_count'] += 1
                cache_entry['last_accessed'] = datetime.now()
                return cache_entry['data'], True
            else:
                # è¿‡æœŸï¼Œåˆ é™¤
                del self._cache[key]
        
        self._cache_stats['misses'] += 1
        return None, False
    
    def set(self, key: str, data: Any, metadata: Dict[str, Any] = None) -> bool:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if metadata is None:
            metadata = {}
        
        # æ·»åŠ æ•°æ®å¤§å°ä¿¡æ¯
        if 'size' not in metadata:
            metadata['size'] = len(str(data))
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç¼“å­˜
        if not self._strategy.should_cache(key, data, metadata):
            return False
        
        # è·å–TTLå’Œä¼˜å…ˆçº§
        ttl = self._strategy.get_ttl(key, data, metadata)
        priority = self._strategy.get_priority(key, data, metadata)
        
        # åˆ›å»ºç¼“å­˜æ¡ç›®
        cache_entry = {
            'data': data,
            'metadata': metadata,
            'priority': priority,
            'created_at': datetime.now(),
            'expires_at': datetime.now() + timedelta(seconds=ttl),
            'last_accessed': datetime.now(),
            'access_count': 1,
            'ttl': ttl
        }
        
        self._cache[key] = cache_entry
        
        # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶ï¼ˆç®€å•å®ç°ï¼‰
        if len(self._cache) > 1000:  # æœ€å¤§1000ä¸ªæ¡ç›®
            self._evict_entries()
        
        return True
    
    def _evict_entries(self) -> None:
        """æ·˜æ±°ç¼“å­˜æ¡ç›®"""
        # æŒ‰ä¼˜å…ˆçº§å’Œæœ€åè®¿é—®æ—¶é—´æ’åº
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: (x[1]['priority'], x[1]['last_accessed']),
            reverse=False
        )
        
        # åˆ é™¤ä¼˜å…ˆçº§æœ€ä½çš„10%æ¡ç›®
        evict_count = len(self._cache) // 10
        for i in range(evict_count):
            key, _ = sorted_entries[i]
            del self._cache[key]
            self._cache_stats['evictions'] += 1
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self._cache_stats['total_requests']
        hit_rate = (self._cache_stats['hits'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'strategy': self._strategy.get_strategy_name(),
            'cache_size': len(self._cache),
            'hit_rate': hit_rate,
            **self._cache_stats
        }


# ==================== æ¼”ç¤ºå‡½æ•° ====================

def demo_file_compression():
    """æ–‡ä»¶å‹ç¼©æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ“ æ–‡ä»¶å‹ç¼©ç­–ç•¥ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    manager = FileCompressionManager()
    
    # æ¨¡æ‹Ÿå‹ç¼©ä¸åŒç±»å‹çš„æ–‡ä»¶
    test_files = [
        "document.txt",
        "data.json",
        "image.jpg",
        "archive.zip",
        "log.log",
        "cache.tmp"
    ]
    
    for file_path in test_files:
        print(f"\n" + "=" * 40)
        result = manager.compress_file(file_path)
        
        if not result['success']:
            print(f"âŒ å‹ç¼©å¤±è´¥: {result['error']}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\n" + "=" * 40)
    print("ğŸ“Š å‹ç¼©ç»Ÿè®¡ä¿¡æ¯:")
    stats = manager.get_compression_statistics()
    
    if stats:
        print(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   æ€»å‹ç¼©ç‡: {stats['overall_compression_ratio']:.1f}%")
        print(f"   å¹³å‡å‹ç¼©æ—¶é—´: {stats['average_time']:.3f} ç§’")
        
        print(f"\n   å„ç­–ç•¥ç»Ÿè®¡:")
        for strategy, strategy_stats in stats['strategy_statistics'].items():
            print(f"     {strategy}: {strategy_stats['count']} ä¸ªæ–‡ä»¶, "
                  f"å¹³å‡å‹ç¼©ç‡ {strategy_stats['avg_ratio']:.1f}%")


def demo_cache_strategies():
    """ç¼“å­˜ç­–ç•¥æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ—„ï¸ ç¼“å­˜ç­–ç•¥ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    # æµ‹è¯•ä¸åŒç¼“å­˜ç­–ç•¥
    strategies = [
        LRUCacheStrategy(),
        TTLCacheStrategy(default_ttl=1800),
        AdaptiveCacheStrategy()
    ]
    
    for strategy in strategies:
        print(f"\næµ‹è¯• {strategy.get_strategy_name()}:")
        manager = CacheManager(strategy)
        
        # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
        test_data = [
            ('user:123', {'name': 'Alice', 'age': 25}, {'type': 'user_profile', 'importance': 'high'}),
            ('product:456', {'name': 'iPhone', 'price': 999}, {'type': 'product_info', 'importance': 'normal'}),
            ('search:python', ['result1', 'result2'], {'type': 'search_result', 'importance': 'low'}),
            ('api:weather', {'temp': 25, 'humidity': 60}, {'type': 'api_response', 'importance': 'normal'}),
        ]
        
        # è®¾ç½®ç¼“å­˜
        for key, data, metadata in test_data:
            success = manager.set(key, data, metadata)
            print(f"   è®¾ç½®ç¼“å­˜ {key}: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # è·å–ç¼“å­˜
        for key, _, _ in test_data:
            data, hit = manager.get(key)
            print(f"   è·å–ç¼“å­˜ {key}: {'å‘½ä¸­' if hit else 'æœªå‘½ä¸­'}")
        
        # æ˜¾ç¤ºç»Ÿè®¡
        stats = manager.get_cache_stats()
        print(f"   ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ç‡ {stats['hit_rate']:.1f}%, å¤§å° {stats['cache_size']}")


if __name__ == "__main__":
    # è¿è¡Œæ–‡ä»¶å‹ç¼©æ¼”ç¤º
    demo_file_compression()
    
    # è¿è¡Œç¼“å­˜ç­–ç•¥æ¼”ç¤º
    demo_cache_strategies()
    
    print("\n" + "=" * 60)
    print("âœ… å®é™…é¡¹ç›®åº”ç”¨æ¼”ç¤ºå®Œæˆ")
    print("ğŸ’¡ å­¦ä¹ è¦ç‚¹:")
    print("   - ç­–ç•¥æ¨¡å¼åœ¨æ–‡ä»¶å¤„ç†ç³»ç»Ÿä¸­çš„åº”ç”¨")
    print("   - æ ¹æ®æ–‡ä»¶ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥")
    print("   - ç¼“å­˜ç­–ç•¥çš„å¤šæ ·åŒ–å®ç°")
    print("   - ç­–ç•¥æ¨¡å¼æé«˜äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§")
    print("=" * 60)
