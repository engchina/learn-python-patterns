#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¿‡æ»¤å’Œè½¬æ¢è¿­ä»£å™¨

æœ¬æ¨¡å—æ¼”ç¤ºäº†è¿­ä»£å™¨çš„è¿‡æ»¤å’Œè½¬æ¢åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. æ¡ä»¶è¿‡æ»¤è¿­ä»£å™¨ - æ ¹æ®æ¡ä»¶ç­›é€‰æ•°æ®
2. æ•°æ®è½¬æ¢è¿­ä»£å™¨ - å¯¹æ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†
3. é“¾å¼æ“ä½œè¿­ä»£å™¨ - å¤šä¸ªè¿­ä»£å™¨çš„ç»„åˆä½¿ç”¨
4. ç®¡é“å¼æ•°æ®å¤„ç† - å‡½æ•°å¼ç¼–ç¨‹é£æ ¼

ä½œè€…: Assistant
æ—¥æœŸ: 2024-01-20
"""

from typing import Any, Callable, Iterator, Iterable, TypeVar, Generic
from functools import reduce
import re

T = TypeVar('T')
U = TypeVar('U')


class FilterIterator(Generic[T]):
    """æ¡ä»¶è¿‡æ»¤è¿­ä»£å™¨"""
    
    def __init__(self, iterable: Iterable[T], predicate: Callable[[T], bool]):
        self.iterator = iter(iterable)
        self.predicate = predicate
        self.filtered_count = 0
        self.total_count = 0
    
    def __iter__(self) -> 'FilterIterator[T]':
        return self
    
    def __next__(self) -> T:
        while True:
            try:
                item = next(self.iterator)
                self.total_count += 1
                
                if self.predicate(item):
                    self.filtered_count += 1
                    return item
                # å¦‚æœä¸æ»¡è¶³æ¡ä»¶ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
            except StopIteration:
                print(f"ğŸ” è¿‡æ»¤å®Œæˆ: {self.filtered_count}/{self.total_count} é¡¹é€šè¿‡è¿‡æ»¤")
                raise
    
    def get_stats(self) -> dict:
        """è·å–è¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'filtered': self.filtered_count,
            'total': self.total_count,
            'filter_rate': self.filtered_count / self.total_count if self.total_count > 0 else 0
        }


class TransformIterator(Generic[T, U]):
    """æ•°æ®è½¬æ¢è¿­ä»£å™¨"""
    
    def __init__(self, iterable: Iterable[T], transform_func: Callable[[T], U]):
        self.iterator = iter(iterable)
        self.transform_func = transform_func
        self.transform_count = 0
    
    def __iter__(self) -> 'TransformIterator[T, U]':
        return self
    
    def __next__(self) -> U:
        try:
            item = next(self.iterator)
            self.transform_count += 1
            transformed = self.transform_func(item)
            return transformed
        except StopIteration:
            print(f"ğŸ”„ è½¬æ¢å®Œæˆ: å…±è½¬æ¢ {self.transform_count} é¡¹")
            raise


class ChainIterator:
    """é“¾å¼è¿­ä»£å™¨ - è¿æ¥å¤šä¸ªè¿­ä»£å™¨"""
    
    def __init__(self, *iterables):
        self.iterables = iterables
        self.current_iterator = None
        self.iterator_index = 0
        self.total_items = 0
    
    def __iter__(self) -> 'ChainIterator':
        self.iterator_index = 0
        self.total_items = 0
        if self.iterables:
            self.current_iterator = iter(self.iterables[0])
        return self
    
    def __next__(self) -> Any:
        while self.iterator_index < len(self.iterables):
            try:
                if self.current_iterator is None:
                    self.current_iterator = iter(self.iterables[self.iterator_index])
                
                item = next(self.current_iterator)
                self.total_items += 1
                return item
            except StopIteration:
                # å½“å‰è¿­ä»£å™¨è€—å°½ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª
                self.iterator_index += 1
                self.current_iterator = None
        
        print(f"ğŸ”— é“¾å¼è¿­ä»£å®Œæˆ: å…±å¤„ç† {self.total_items} é¡¹")
        raise StopIteration


class BatchIterator(Generic[T]):
    """æ‰¹å¤„ç†è¿­ä»£å™¨ - å°†æ•°æ®åˆ†æ‰¹å¤„ç†"""
    
    def __init__(self, iterable: Iterable[T], batch_size: int):
        self.iterator = iter(iterable)
        self.batch_size = batch_size
        self.batch_count = 0
    
    def __iter__(self) -> 'BatchIterator[T]':
        return self
    
    def __next__(self) -> list[T]:
        batch = []
        try:
            for _ in range(self.batch_size):
                item = next(self.iterator)
                batch.append(item)
        except StopIteration:
            if batch:
                self.batch_count += 1
                print(f"ğŸ“¦ æœ€åä¸€æ‰¹: {len(batch)} é¡¹ (ç¬¬{self.batch_count}æ‰¹)")
                return batch
            else:
                print(f"ğŸ“¦ æ‰¹å¤„ç†å®Œæˆ: å…± {self.batch_count} æ‰¹")
                raise
        
        self.batch_count += 1
        return batch


class DataPipeline:
    """æ•°æ®å¤„ç†ç®¡é“ - ç»„åˆå¤šç§æ“ä½œ"""
    
    def __init__(self, data: Iterable[Any]):
        self.data = data
        self.operations = []
    
    def filter(self, predicate: Callable[[Any], bool]) -> 'DataPipeline':
        """æ·»åŠ è¿‡æ»¤æ“ä½œ"""
        self.operations.append(('filter', predicate))
        return self
    
    def map(self, transform_func: Callable[[Any], Any]) -> 'DataPipeline':
        """æ·»åŠ è½¬æ¢æ“ä½œ"""
        self.operations.append(('map', transform_func))
        return self
    
    def batch(self, size: int) -> 'DataPipeline':
        """æ·»åŠ æ‰¹å¤„ç†æ“ä½œ"""
        self.operations.append(('batch', size))
        return self
    
    def execute(self) -> Iterator[Any]:
        """æ‰§è¡Œç®¡é“æ“ä½œ"""
        result = iter(self.data)
        
        for operation, param in self.operations:
            if operation == 'filter':
                result = FilterIterator(result, param)
            elif operation == 'map':
                result = TransformIterator(result, param)
            elif operation == 'batch':
                result = BatchIterator(result, param)
        
        return result


class TextProcessor:
    """æ–‡æœ¬å¤„ç†å™¨ - æ¼”ç¤ºå¤æ‚çš„è¿‡æ»¤å’Œè½¬æ¢"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
        text = re.sub(r'\s+', ' ', text.strip())
        return text
    
    @staticmethod
    def extract_words(text: str) -> list[str]:
        """æå–å•è¯"""
        return re.findall(r'\b\w+\b', text.lower())
    
    @staticmethod
    def is_valid_word(word: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆå•è¯"""
        return len(word) >= 2 and word.isalpha()
    
    @staticmethod
    def word_length_category(word: str) -> str:
        """å•è¯é•¿åº¦åˆ†ç±»"""
        length = len(word)
        if length <= 3:
            return "çŸ­è¯"
        elif length <= 6:
            return "ä¸­è¯"
        else:
            return "é•¿è¯"


def demo_filter_iterator():
    """æ¼”ç¤ºè¿‡æ»¤è¿­ä»£å™¨"""
    print("=" * 50)
    print("ğŸ” è¿‡æ»¤è¿­ä»£å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # æ•°å­—è¿‡æ»¤ç¤ºä¾‹
    numbers = range(1, 21)
    print(f"åŸå§‹æ•°æ®: {list(numbers)}")
    
    # è¿‡æ»¤å¶æ•°
    even_filter = FilterIterator(numbers, lambda x: x % 2 == 0)
    even_numbers = list(even_filter)
    print(f"å¶æ•°: {even_numbers}")
    print(f"è¿‡æ»¤ç»Ÿè®¡: {even_filter.get_stats()}")
    
    # è¿‡æ»¤è´¨æ•°
    def is_prime(n):
        if n < 2:
            return False
        for i in range(2, int(n ** 0.5) + 1):
            if n % i == 0:
                return False
        return True
    
    prime_filter = FilterIterator(range(1, 21), is_prime)
    prime_numbers = list(prime_filter)
    print(f"è´¨æ•°: {prime_numbers}")
    print(f"è¿‡æ»¤ç»Ÿè®¡: {prime_filter.get_stats()}")


def demo_transform_iterator():
    """æ¼”ç¤ºè½¬æ¢è¿­ä»£å™¨"""
    print("\n" + "=" * 50)
    print("ğŸ”„ è½¬æ¢è¿­ä»£å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # æ•°å­—è½¬æ¢ç¤ºä¾‹
    numbers = [1, 2, 3, 4, 5]
    print(f"åŸå§‹æ•°æ®: {numbers}")
    
    # å¹³æ–¹è½¬æ¢
    square_transform = TransformIterator(numbers, lambda x: x ** 2)
    squares = list(square_transform)
    print(f"å¹³æ–¹: {squares}")
    
    # å­—ç¬¦ä¸²è½¬æ¢
    words = ["hello", "world", "python", "iterator"]
    print(f"\nåŸå§‹å•è¯: {words}")
    
    # è½¬æ¢ä¸ºå¤§å†™å¹¶æ·»åŠ é•¿åº¦ä¿¡æ¯
    word_transform = TransformIterator(
        words, 
        lambda w: f"{w.upper()}({len(w)})"
    )
    transformed_words = list(word_transform)
    print(f"è½¬æ¢å: {transformed_words}")


def demo_chain_iterator():
    """æ¼”ç¤ºé“¾å¼è¿­ä»£å™¨"""
    print("\n" + "=" * 50)
    print("ğŸ”— é“¾å¼è¿­ä»£å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # è¿æ¥å¤šä¸ªæ•°æ®æº
    list1 = [1, 2, 3]
    list2 = ['a', 'b', 'c']
    list3 = [10, 20, 30]
    
    print(f"åˆ—è¡¨1: {list1}")
    print(f"åˆ—è¡¨2: {list2}")
    print(f"åˆ—è¡¨3: {list3}")
    
    # é“¾å¼è¿æ¥
    chain_iter = ChainIterator(list1, list2, list3)
    chained_data = list(chain_iter)
    print(f"é“¾å¼ç»“æœ: {chained_data}")


def demo_batch_iterator():
    """æ¼”ç¤ºæ‰¹å¤„ç†è¿­ä»£å™¨"""
    print("\n" + "=" * 50)
    print("ğŸ“¦ æ‰¹å¤„ç†è¿­ä»£å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # å¤§æ•°æ®é›†åˆ†æ‰¹å¤„ç†
    large_dataset = range(1, 26)  # 1åˆ°25
    print(f"æ•°æ®é›†å¤§å°: {len(list(large_dataset))}")
    
    # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹5ä¸ª
    batch_iter = BatchIterator(large_dataset, batch_size=5)
    
    print("åˆ†æ‰¹å¤„ç†ç»“æœ:")
    for batch_num, batch in enumerate(batch_iter, 1):
        print(f"  ç¬¬{batch_num}æ‰¹: {batch}")


def demo_data_pipeline():
    """æ¼”ç¤ºæ•°æ®å¤„ç†ç®¡é“"""
    print("\n" + "=" * 50)
    print("ğŸš° æ•°æ®å¤„ç†ç®¡é“æ¼”ç¤º")
    print("=" * 50)
    
    # åŸå§‹æ•°æ®
    data = range(1, 21)
    print(f"åŸå§‹æ•°æ®: {list(data)}")
    
    # æ„å»ºå¤„ç†ç®¡é“
    pipeline = (DataPipeline(data)
                .filter(lambda x: x % 2 == 0)  # è¿‡æ»¤å¶æ•°
                .map(lambda x: x ** 2)          # å¹³æ–¹
                .batch(3))                      # åˆ†æ‰¹ï¼Œæ¯æ‰¹3ä¸ª
    
    print("ç®¡é“å¤„ç†ç»“æœ:")
    for batch in pipeline.execute():
        print(f"  æ‰¹æ¬¡: {batch}")


def demo_text_processing():
    """æ¼”ç¤ºæ–‡æœ¬å¤„ç†"""
    print("\n" + "=" * 50)
    print("ğŸ“ æ–‡æœ¬å¤„ç†æ¼”ç¤º")
    print("=" * 50)
    
    # ç¤ºä¾‹æ–‡æœ¬
    texts = [
        "Hello World! This is a sample text.",
        "Python is great for data processing.",
        "Iterator pattern provides efficient data traversal.",
        "   Extra   spaces   should   be   cleaned   ",
        "Short words: a, I, to, be, or, not"
    ]
    
    print("åŸå§‹æ–‡æœ¬:")
    for i, text in enumerate(texts, 1):
        print(f"  {i}. {text}")
    
    # æ–‡æœ¬æ¸…ç†ç®¡é“
    processor = TextProcessor()
    
    # æ¸…ç†æ–‡æœ¬
    cleaned_texts = list(TransformIterator(texts, processor.clean_text))
    print("\næ¸…ç†åçš„æ–‡æœ¬:")
    for i, text in enumerate(cleaned_texts, 1):
        print(f"  {i}. {text}")
    
    # æå–æ‰€æœ‰å•è¯
    all_words = []
    for text in cleaned_texts:
        all_words.extend(processor.extract_words(text))
    
    print(f"\næå–çš„æ‰€æœ‰å•è¯ ({len(all_words)} ä¸ª):")
    print(f"  {all_words}")
    
    # è¿‡æ»¤æœ‰æ•ˆå•è¯
    valid_words = list(FilterIterator(all_words, processor.is_valid_word))
    print(f"\næœ‰æ•ˆå•è¯ ({len(valid_words)} ä¸ª):")
    print(f"  {valid_words}")
    
    # å•è¯åˆ†ç±»
    word_categories = list(TransformIterator(
        valid_words, 
        lambda w: f"{w}({processor.word_length_category(w)})"
    ))
    print(f"\nå•è¯åˆ†ç±»:")
    print(f"  {word_categories}")


if __name__ == "__main__":
    print("ğŸ¯ è¿‡æ»¤å’Œè½¬æ¢è¿­ä»£å™¨æ¼”ç¤º")
    
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    demo_filter_iterator()
    demo_transform_iterator()
    demo_chain_iterator()
    demo_batch_iterator()
    demo_data_pipeline()
    demo_text_processing()
    
    print("\n" + "=" * 50)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("ğŸ’¡ æç¤º: è¿™äº›è¿­ä»£å™¨å¯ä»¥ç»„åˆä½¿ç”¨ï¼Œæ„å»ºå¼ºå¤§çš„æ•°æ®å¤„ç†ç®¡é“")
    print("=" * 50)
